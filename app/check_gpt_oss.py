#!/usr/bin/env python3
"""
å¿«é€Ÿæª¢æŸ¥ GPT-OSS æ¨¡å‹å¯ç”¨æ€§å’Œä¸‰å…ƒçµ„æŠ½å–åŠŸèƒ½
"""

import requests
import json
from config import OLLAMA_BASE_URL

def check_gpt_oss_available():
    """æª¢æŸ¥ GPT-OSS æ¨¡å‹æ˜¯å¦å¯ç”¨"""
    print("ğŸ” æª¢æŸ¥ GPT-OSS æ¨¡å‹å¯ç”¨æ€§...")
    
    try:
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=10)
        response.raise_for_status()
        
        data = response.json()
        models = data.get('models', [])
        
        gpt_oss_models = [m for m in models if 'gpt-oss' in m.get('name', '').lower()]
        
        if gpt_oss_models:
            print(f"âœ… æ‰¾åˆ° {len(gpt_oss_models)} å€‹ GPT-OSS æ¨¡å‹:")
            for model in gpt_oss_models:
                name = model.get('name', 'Unknown')
                size = model.get('size', 'Unknown')
                print(f"   - {name} (å¤§å°: {size})")
            return gpt_oss_models[0]['name']  # è¿”å›ç¬¬ä¸€å€‹æ‰¾åˆ°çš„æ¨¡å‹
        else:
            print("âŒ æ²’æœ‰æ‰¾åˆ° GPT-OSS æ¨¡å‹")
            print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
            for model in models:
                name = model.get('name', 'Unknown')
                print(f"   - {name}")
            return None
            
    except Exception as e:
        print(f"âŒ æª¢æŸ¥å¤±æ•—: {e}")
        return None

def test_gpt_oss_triplet_extraction(model_name):
    """æ¸¬è©¦ GPT-OSS çš„ä¸‰å…ƒçµ„æŠ½å–"""
    print(f"\nğŸ§ª æ¸¬è©¦ {model_name} çš„ä¸‰å…ƒçµ„æŠ½å–...")
    
    test_text = "MIAT æ–¹æ³•è«–è‘—é‡åœ¨ç³»çµ±çš„éšå±¤å¼æ¨¡çµ„åŒ–çš„æ¶æ§‹è¨­è¨ˆï¼Œä»¥åŠæ¼”ç®—æ³•çš„é›¢æ•£äº‹ä»¶å»ºæ¨¡ï¼Œæœ€å¾Œåˆæˆå¯ç¶­è­·ã€å¯æ“´å±•çš„ç³»çµ±ç¨‹å¼ç¢¼ã€‚"
    
    prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜æŠ½å–åŠ©æ‰‹ã€‚è«‹å¾çµ¦å®šçš„æ–‡æœ¬ä¸­æŠ½å–çŸ¥è­˜ä¸‰å…ƒçµ„ã€‚

ä»»å‹™ï¼š
1. ä»”ç´°é–±è®€æ–‡æœ¬
2. è­˜åˆ¥å‡ºé‡è¦çš„å¯¦é«”ï¼ˆäººç‰©ã€åœ°é»ã€æ¦‚å¿µã€æ–¹æ³•ç­‰ï¼‰
3. è­˜åˆ¥å¯¦é«”ä¹‹é–“çš„é—œä¿‚
4. ä»¥ (ä¸»é«”, é—œä¿‚, å®¢é«”) çš„æ ¼å¼è¼¸å‡ºä¸‰å…ƒçµ„

è¦æ±‚ï¼š
- ä¸»é«”å’Œå®¢é«”æ‡‰è©²æ˜¯å…·é«”çš„å¯¦é«”æˆ–æ¦‚å¿µ
- é—œä¿‚æ‡‰è©²æ¸…æ¥šè¡¨é”å…©è€…ä¹‹é–“çš„è¯ç¹«
- é¿å…éæ–¼æŠ½è±¡æˆ–æ¨¡ç³Šçš„é—œä¿‚
- ç¢ºä¿ä¸‰å…ƒçµ„åœ¨èªç¾©ä¸Šæ˜¯æ­£ç¢ºçš„

è«‹ä»¥ä»¥ä¸‹JSONæ ¼å¼å›æ‡‰ï¼š
[
    {{"subject": "ä¸»é«”åç¨±", "predicate": "é—œä¿‚æè¿°", "object": "å®¢é«”åç¨±"}},
    {{"subject": "ä¸»é«”åç¨±", "predicate": "é—œä¿‚æè¿°", "object": "å®¢é«”åç¨±"}}
]

åªå›æ‡‰JSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–èªªæ˜æ–‡å­—ã€‚

ç¾åœ¨è™•ç†æ–‡æœ¬ï¼š{test_text}"""

    url = f"{OLLAMA_BASE_URL}/api/generate"
    payload = {
        "model": model_name,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.1,
            "top_p": 0.9,
            "num_predict": 1000
        }
    }
    
    try:
        print(f"ğŸ“¤ ç™¼é€æ¸¬è©¦è«‹æ±‚...")
        response = requests.post(url, json=payload, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        response_text = result.get('response', '').strip()
        
        print(f"ğŸ“¥ æ¨¡å‹å›æ‡‰:")
        print(f"å›æ‡‰å…§å®¹: {response_text}")
        print(f"å›æ‡‰é•·åº¦: {len(response_text)} å­—ç¬¦")
        
        # å˜—è©¦è§£æ JSON
        try:
            start = response_text.find('[')
            end = response_text.rfind(']') + 1
            
            if start >= 0 and end > start:
                json_str = response_text[start:end]
                parsed_json = json.loads(json_str)
                
                print(f"\nâœ… æˆåŠŸè§£æ JSONï¼ŒåŒ…å« {len(parsed_json)} å€‹ä¸‰å…ƒçµ„:")
                for i, item in enumerate(parsed_json, 1):
                    if isinstance(item, dict):
                        subject = item.get('subject', '')
                        predicate = item.get('predicate', '')
                        obj = item.get('object', '')
                        print(f"   {i}. ({subject}) --[{predicate}]--> ({obj})")
                
                return True
            else:
                print("âŒ ç„¡æ³•æ‰¾åˆ°æœ‰æ•ˆçš„ JSON æ ¼å¼")
                return False
                
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±æ•—: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    print("ğŸš€ GPT-OSS æ¨¡å‹å¿«é€Ÿæª¢æŸ¥å·¥å…·")
    print("=" * 50)
    
    # 1. æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§
    model_name = check_gpt_oss_available()
    
    if not model_name:
        print("\nğŸ’¡ å»ºè­°è§£æ±ºæ–¹æ¡ˆ:")
        print("1. ç¢ºä¿å·²ä¸‹è¼‰ GPT-OSS æ¨¡å‹:")
        print("   sudo docker-compose exec ollama ollama pull gpt-oss:20b")
        print("2. æª¢æŸ¥ Ollama æœå‹™æ˜¯å¦æ­£å¸¸é‹è¡Œ:")
        print("   sudo docker-compose ps")
        return False
    
    # 2. æ¸¬è©¦ä¸‰å…ƒçµ„æŠ½å–
    success = test_gpt_oss_triplet_extraction(model_name)
    
    print(f"\n{'='*50}")
    if success:
        print("ğŸ‰ GPT-OSS æ¨¡å‹é‹è¡Œæ­£å¸¸ï¼Œå¯ä»¥æ­£ç¢ºæŠ½å–ä¸‰å…ƒçµ„ï¼")
        print("ç¾åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤é€²è¡Œå®Œæ•´çš„ä¸‰å…ƒçµ„æŠ½å–:")
        print("sudo docker-compose exec app python sentence_triplet_extractor.py")
    else:
        print("âŒ GPT-OSS æ¨¡å‹ç„¡æ³•æ­£ç¢ºæŠ½å–ä¸‰å…ƒçµ„")
        print("è«‹æª¢æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¢ºå®‰è£æˆ–è€ƒæ…®ä½¿ç”¨å…¶ä»–æ¨¡å‹")
    print(f"{'='*50}")
    
    return success

if __name__ == "__main__":
    main()