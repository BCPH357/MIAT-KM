#!/usr/bin/env python3
"""
æ¸¬è©¦ç•¶å‰é…ç½®çš„æ¨¡å‹æ˜¯å¦èƒ½æ­£ç¢ºæŠ½å–ä¸‰å…ƒçµ„
å°ˆé–€é‡å° GPT-OSS æ¨¡å‹é€²è¡Œé©—è­‰
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import requests
import json
from sentence_triplet_extractor import DeepSeekTripletExtractor
from model_adapter import get_model_adapter
from config import OLLAMA_MODEL, OLLAMA_BASE_URL

# æ¸¬è©¦æ–‡æœ¬
TEST_TEXT = "MIAT æ–¹æ³•è«–è‘—é‡åœ¨ç³»çµ±çš„éšå±¤å¼æ¨¡çµ„åŒ–çš„æ¶æ§‹è¨­è¨ˆï¼Œä»¥åŠæ¼”ç®—æ³•çš„é›¢æ•£äº‹ä»¶å»ºæ¨¡ï¼Œæœ€å¾Œåˆæˆå¯ç¶­è­·ã€å¯æ“´å±•çš„ç³»çµ±ç¨‹å¼ç¢¼ã€‚"

def check_model_availability():
    """æª¢æŸ¥ç•¶å‰æ¨¡å‹æ˜¯å¦å¯ç”¨"""
    print(f"ğŸ” æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§: {OLLAMA_MODEL}")
    print(f"ğŸ”— Ollama æœå‹™åœ°å€: {OLLAMA_BASE_URL}")
    
    try:
        # æª¢æŸ¥æ¨¡å‹åˆ—è¡¨
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=10)
        response.raise_for_status()
        
        data = response.json()
        models = data.get('models', [])
        
        print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨ ({len(models)} å€‹):")
        available_models = []
        for model in models:
            name = model.get('name', 'Unknown')
            size = model.get('size', 'Unknown')
            print(f"  - {name} (å¤§å°: {size})")
            available_models.append(name)
        
        # æª¢æŸ¥ç•¶å‰é…ç½®çš„æ¨¡å‹æ˜¯å¦åœ¨åˆ—è¡¨ä¸­
        if OLLAMA_MODEL in available_models:
            print(f"âœ… ç•¶å‰æ¨¡å‹ {OLLAMA_MODEL} å¯ç”¨")
            return True
        else:
            print(f"âŒ ç•¶å‰æ¨¡å‹ {OLLAMA_MODEL} ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­")
            
            # å°‹æ‰¾é¡ä¼¼çš„æ¨¡å‹
            similar_models = [m for m in available_models if 'gpt-oss' in m.lower()]
            if similar_models:
                print(f"ğŸ’¡ å»ºè­°ä½¿ç”¨é¡ä¼¼çš„æ¨¡å‹: {similar_models}")
            
            return False
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ ç„¡æ³•é€£æ¥åˆ° Ollama æœå‹™: {e}")
        return False
    except Exception as e:
        print(f"âŒ æª¢æŸ¥æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def test_simple_generation():
    """æ¸¬è©¦ç°¡å–®çš„æ–‡æœ¬ç”Ÿæˆ"""
    print(f"\nğŸ§ª æ¸¬è©¦åŸºæœ¬ç”ŸæˆåŠŸèƒ½")
    print("-" * 50)
    
    url = f"{OLLAMA_BASE_URL}/api/generate"
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": "è«‹å›ç­”ï¼šä½ æ˜¯ä»€éº¼æ¨¡å‹ï¼Ÿ",
        "stream": False,
        "options": {
            "temperature": 0.1,
            "num_predict": 100
        }
    }
    
    try:
        print(f"ç™¼é€æ¸¬è©¦è«‹æ±‚åˆ° {OLLAMA_MODEL}...")
        response = requests.post(url, json=payload, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        response_text = result.get('response', '')
        
        print(f"âœ… æ¨¡å‹å›æ‡‰: {response_text[:200]}...")
        print(f"ğŸ“Š å›æ‡‰é•·åº¦: {len(response_text)} å­—ç¬¦")
        return True
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ è«‹æ±‚å¤±æ•—: {e}")
        return False
    except Exception as e:
        print(f"âŒ è™•ç†å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def test_triplet_extraction():
    """æ¸¬è©¦ä¸‰å…ƒçµ„æŠ½å–åŠŸèƒ½"""
    print(f"\nğŸ¯ æ¸¬è©¦ä¸‰å…ƒçµ„æŠ½å–åŠŸèƒ½")
    print("-" * 50)
    print(f"ä½¿ç”¨æ¨¡å‹: {OLLAMA_MODEL}")
    print(f"æ¸¬è©¦æ–‡æœ¬: {TEST_TEXT}")
    
    try:
        # æª¢æŸ¥é©é…å™¨é¡å‹
        adapter = get_model_adapter(OLLAMA_MODEL)
        print(f"ğŸ“ é©é…å™¨é¡å‹: {type(adapter).__name__}")
        
        # å‰µå»ºæŠ½å–å™¨
        extractor = DeepSeekTripletExtractor()
        
        # åŸ·è¡ŒæŠ½å–
        print(f"\né–‹å§‹æŠ½å–ä¸‰å…ƒçµ„...")
        triplets = extractor.extract_triplets_from_sentence(TEST_TEXT)
        
        if triplets:
            print(f"\nâœ… æˆåŠŸæŠ½å– {len(triplets)} å€‹ä¸‰å…ƒçµ„:")
            for i, (subject, predicate, obj) in enumerate(triplets, 1):
                print(f"   {i}. ({subject}) --[{predicate}]--> ({obj})")
            return True
        else:
            print(f"\nâŒ æ²’æœ‰æŠ½å–åˆ°ä»»ä½•ä¸‰å…ƒçµ„")
            return False
            
    except Exception as e:
        print(f"âŒ ä¸‰å…ƒçµ„æŠ½å–å¤±æ•—: {e}")
        return False

def test_adapter_formats():
    """æ¸¬è©¦ä¸åŒé©é…å™¨çš„æ ¼å¼"""
    print(f"\nğŸ”§ æ¸¬è©¦é©é…å™¨æ ¼å¼")
    print("-" * 50)
    
    # æ¸¬è©¦ç•¶å‰æ¨¡å‹çš„é©é…å™¨
    adapter = get_model_adapter(OLLAMA_MODEL)
    print(f"ç•¶å‰æ¨¡å‹é©é…å™¨: {type(adapter).__name__}")
    
    print(f"\nç³»çµ± Prompt é è¦½:")
    prompt = adapter.get_system_prompt()
    print(prompt[:300] + "..." if len(prompt) > 300 else prompt)
    
    print(f"\nAPI é¸é …:")
    options = adapter.get_api_options()
    print(json.dumps(options, indent=2))

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ ç•¶å‰æ¨¡å‹æ¸¬è©¦ç¨‹å¼")
    print("=" * 60)
    print(f"ç›®æ¨™æ¨¡å‹: {OLLAMA_MODEL}")
    print(f"Ollama æœå‹™: {OLLAMA_BASE_URL}")
    print("=" * 60)
    
    # 1. æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§
    if not check_model_availability():
        print("\nâŒ æ¨¡å‹ä¸å¯ç”¨ï¼Œç„¡æ³•ç¹¼çºŒæ¸¬è©¦")
        return False
    
    # 2. æ¸¬è©¦åŸºæœ¬ç”Ÿæˆ
    if not test_simple_generation():
        print("\nâŒ åŸºæœ¬ç”Ÿæˆæ¸¬è©¦å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒ")
        return False
    
    # 3. æ¸¬è©¦é©é…å™¨æ ¼å¼
    test_adapter_formats()
    
    # 4. æ¸¬è©¦ä¸‰å…ƒçµ„æŠ½å–
    success = test_triplet_extraction()
    
    print(f"\n{'='*60}")
    if success:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼æ¨¡å‹é‹è¡Œæ­£å¸¸")
    else:
        print("âŒ ä¸‰å…ƒçµ„æŠ½å–æ¸¬è©¦å¤±æ•—")
    print(f"{'='*60}")
    
    return success

if __name__ == "__main__":
    main()