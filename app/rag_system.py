from knowledge_retriever import Neo4jKnowledgeRetriever
from ollama_client import OllamaClient
from vector_rag_processor import VectorRAGProcessor
import time
from typing import Dict, Any
from config import NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD, OLLAMA_BASE_URL, OLLAMA_MODEL

class RAGSystem:
    def __init__(self, 
                 neo4j_uri: str = NEO4J_URI,
                 neo4j_user: str = NEO4J_USER, 
                 neo4j_password: str = NEO4J_PASSWORD,
                 ollama_url: str = OLLAMA_BASE_URL,
                 model_name: str = OLLAMA_MODEL):
        
        self.knowledge_retriever = Neo4jKnowledgeRetriever(neo4j_uri, neo4j_user, neo4j_password)
        self.ollama_client = OllamaClient(ollama_url)
        self.model_name = model_name
        
        # åˆå§‹åŒ–Vector RAGè™•ç†å™¨
        try:
            self.vector_rag_processor = VectorRAGProcessor()
            self.vector_available = True
        except Exception as e:
            print(f"è­¦å‘Š: Vector RAGåˆå§‹åŒ–å¤±æ•—: {e}")
            self.vector_rag_processor = None
            self.vector_available = False
        
        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
        if not self.ollama_client.check_model_available(model_name):
            print(f"è­¦å‘Š: æ¨¡å‹ {model_name} ä¸å¯ç”¨")
            available_models = self.ollama_client.list_models()
            if not available_models.get("error"):
                print("å¯ç”¨æ¨¡å‹:", [m["name"] for m in available_models.get("models", [])])
    
    def answer_question(self, user_query: str, use_hybrid: bool = False, use_vector: bool = False, use_hybrid_all: bool = False) -> Dict[str, Any]:
        """
        å›ç­”ç”¨æˆ¶å•é¡Œ
        """
        start_time = time.time()
        
        result = {
            "query": user_query,
            "use_hybrid": use_hybrid,
            "use_vector": use_vector,
            "use_hybrid_all": use_hybrid_all,
            "knowledge_context": "",
            "answer": "",
            "thinking": "",
            "retrieval_time": 0,
            "generation_time": 0,
            "total_time": 0,
            "knowledge_items_count": 0,
            "cypher_query": "",
            "context_data": [],
            "vector_results": []
        }
        
        if use_hybrid_all:
            # ä½¿ç”¨æ··åˆæª¢ç´¢æ¨¡å¼ï¼šåŒæ™‚ä½¿ç”¨çŸ¥è­˜åœ–è­œå’Œå‘é‡æª¢ç´¢
            retrieval_start = time.time()
            
            # ç²å–çŸ¥è­˜åœ–è­œçµæœ
            hybrid_result = self.knowledge_retriever.hybrid_search(user_query, self.ollama_client)
            
            # ç²å–å‘é‡æª¢ç´¢çµæœ
            vector_results = []
            if self.vector_available:
                try:
                    vector_search = self.vector_rag_processor.search_documents(user_query, n_results=5)
                    vector_results = vector_search['results']
                except Exception as e:
                    print(f"å‘é‡æª¢ç´¢å¤±æ•—: {e}")
            
            retrieval_time = time.time() - retrieval_start
            
            # çµ„åˆçŸ¥è­˜ä¸Šä¸‹æ–‡
            combined_context = f"CypheræŸ¥è©¢: {hybrid_result['cypher_query']}\næª¢ç´¢åˆ°çš„åœ–è­œæ•¸æ“š: {hybrid_result['context']}\n"
            if vector_results:
                combined_context += "\nå‘é‡æª¢ç´¢çµæœ:\n"
                for i, vr in enumerate(vector_results, 1):
                    combined_context += f"{i}. {vr['content'][:1000]}... (ä¾†æº: {vr['metadata'].get('source_file', 'Unknown')})\n"
            
            # ä½¿ç”¨çµ„åˆä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”
            generation_start = time.time()
            cot_response = self.ollama_client.rag_generate(
                model=self.model_name,
                user_query=user_query,
                knowledge_context=combined_context,
                temperature=0.7
            )
            generation_time = time.time() - generation_start
            
            result["answer"] = cot_response["answer"]
            result["thinking"] = cot_response["thinking"]
            result["cypher_query"] = hybrid_result["cypher_query"]
            result["context_data"] = hybrid_result["context"]
            result["vector_results"] = vector_results
            result["knowledge_context"] = combined_context
            result["retrieval_time"] = retrieval_time
            result["generation_time"] = generation_time
            result["knowledge_items_count"] = len(hybrid_result["context"]) + len(vector_results)
            
        elif use_vector:
            # ç´”å‘é‡RAGæ¨¡å¼
            if not self.vector_available:
                result["answer"] = "å‘é‡RAGç³»çµ±ä¸å¯ç”¨ï¼Œè«‹æª¢æŸ¥é…ç½®"
                return result
            
            retrieval_start = time.time()
            vector_search = self.vector_rag_processor.search_documents(user_query, n_results=5)
            retrieval_time = time.time() - retrieval_start
            
            vector_results = vector_search['results']
            
            if vector_results:
                # çµ„ç¹”å‘é‡æª¢ç´¢ä¸Šä¸‹æ–‡
                vector_context = "å¾å‘é‡æ•¸æ“šåº«æª¢ç´¢åˆ°çš„ç›¸é—œä¿¡æ¯:\n"
                for i, vr in enumerate(vector_results, 1):
                    vector_context += f"{i}. {vr['content']} (ç›¸ä¼¼åº¦: {vr['similarity_score']:.3f}, ä¾†æº: {vr['metadata'].get('source_file', 'Unknown')})\n"
                
                # ç”Ÿæˆå›ç­”
                generation_start = time.time()
                cot_response = self.ollama_client.rag_generate(
                    model=self.model_name,
                    user_query=user_query,
                    knowledge_context=vector_context,
                    temperature=0.7
                )
                generation_time = time.time() - generation_start
                
                result["answer"] = cot_response["answer"]
                result["thinking"] = cot_response["thinking"]
                result["knowledge_context"] = vector_context
                result["vector_results"] = vector_results
                result["knowledge_items_count"] = len(vector_results)
            else:
                result["answer"] = "å‘é‡æ•¸æ“šåº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œä¿¡æ¯"
            
            result["retrieval_time"] = retrieval_time
            result["generation_time"] = generation_time if 'generation_time' in locals() else 0
            
        elif use_hybrid:
            # ä½¿ç”¨æ··åˆRAGæ¨¡å¼ï¼šLangChainæª¢ç´¢ + è‡ªå®šç¾©ç”Ÿæˆ
            retrieval_start = time.time()
            hybrid_result = self.knowledge_retriever.hybrid_search(user_query, self.ollama_client)
            retrieval_time = time.time() - retrieval_start
            
            result["answer"] = hybrid_result["answer"]
            result["cypher_query"] = hybrid_result["cypher_query"]
            result["context_data"] = hybrid_result["context"]
            result["knowledge_context"] = f"CypheræŸ¥è©¢: {hybrid_result['cypher_query']}\næª¢ç´¢åˆ°çš„æ•¸æ“š: {hybrid_result['context']}"
            result["retrieval_time"] = retrieval_time
            result["generation_time"] = 0  # åŒ…å«åœ¨retrieval_timeä¸­
            result["knowledge_items_count"] = len(hybrid_result["context"]) if isinstance(hybrid_result["context"], list) else 0
            
        else:
            # å¦‚æœæ²’æœ‰æŒ‡å®šæ¨¡å¼ï¼Œæç¤ºç”¨æˆ¶é¸æ“‡
            result["answer"] = "è«‹é¸æ“‡æŸ¥è©¢æ¨¡å¼ï¼šKGã€vector æˆ– hybrid-all"
        
        result["total_time"] = time.time() - start_time
        return result
    
    def interactive_qa(self):
        """
        äº’å‹•å¼å•ç­” - ç°¡åŒ–ç‰ˆï¼Œç›´æ¥ä½¿ç”¨ LangChain
        """
        print("=== RAG çŸ¥è­˜å•ç­”ç³»çµ± (å¢å¼·ç‰ˆ) ===")
        print("ğŸ’¡ ä½¿ç”¨ Ollama + Neo4j çŸ¥è­˜åœ–è­œ + Vector RAG")
        print("\nğŸ”§ å¯ç”¨å‘½ä»¤:")
        print("  'KG <å•é¡Œ>' â†’ ä½¿ç”¨çŸ¥è­˜åœ–è­œæ¨¡å¼")
        print("  'vector <å•é¡Œ>' â†’ ä½¿ç”¨ç´”å‘é‡RAGæ¨¡å¼")
        print("  'hybrid-all <å•é¡Œ>' â†’ ä½¿ç”¨å…¨æ··åˆæ¨¡å¼(çŸ¥è­˜åœ–è­œ+å‘é‡)")
        print("  'compare <å•é¡Œ>' â†’ æ¯”è¼ƒæ‰€æœ‰æ¨¡å¼")
        print("  'quit' æˆ– 'exit' â†’ é€€å‡ºç³»çµ±")
        
        if self.vector_available:
            vector_stats = self.vector_rag_processor.get_database_stats()
            print(f"\nğŸ“Š å‘é‡æ•¸æ“šåº«ç‹€æ…‹: {vector_stats['total_chunks']} chunks, {vector_stats['unique_files']} æ–‡ä»¶")
        else:
            print("\nâš ï¸  å‘é‡RAGä¸å¯ç”¨")
        
        print("-" * 70)
        
        while True:
            try:
                user_input = input("\nè«‹è¼¸å…¥å•é¡Œ: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    break
                
                elif user_input.startswith('KG ') or user_input.startswith('kg '):
                    # ä½¿ç”¨çŸ¥è­˜åœ–è­œæ¨¡å¼
                    query = user_input[3:].strip()
                    if query:
                        result = self.answer_question(query, use_hybrid=True)
                        self._print_hybrid_result(result)
                    else:
                        print("è«‹æä¾›å•é¡Œ")
                
                elif user_input.startswith('vector '):
                    # ä½¿ç”¨ç´”å‘é‡RAGæ¨¡å¼
                    query = user_input[7:].strip()
                    if query:
                        if self.vector_available:
                            result = self.answer_question(query, use_vector=True)
                            self._print_vector_result(result)
                        else:
                            print("å‘é‡RAGç³»çµ±ä¸å¯ç”¨")
                    else:
                        print("è«‹æä¾›å•é¡Œ")
                
                elif user_input.startswith('hybrid-all '):
                    # ä½¿ç”¨å…¨æ··åˆæ¨¡å¼
                    query = user_input[11:].strip()
                    if query:
                        if self.vector_available:
                            result = self.answer_question(query, use_hybrid_all=True)
                            self._print_hybrid_all_result(result)
                        else:
                            print("å‘é‡RAGç³»çµ±ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨çŸ¥è­˜åœ–è­œæ¨¡å¼")
                            result = self.answer_question(query, use_hybrid=True)
                            self._print_hybrid_result(result)
                    else:
                        print("è«‹æä¾›å•é¡Œ")
                
                elif user_input.startswith('compare '):
                    # æ¯”è¼ƒä¸‰ç¨®æ¨¡å¼
                    query = user_input[8:].strip()
                    if query:
                        self._compare_three_modes(query)
                    else:
                        print("è«‹æä¾›å•é¡Œ")
                
                elif user_input:
                    # æç¤ºç”¨æˆ¶ä½¿ç”¨æ­£ç¢ºçš„å‘½ä»¤æ ¼å¼
                    print("è«‹ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ ¼å¼:")
                    print("  'KG <å•é¡Œ>' - çŸ¥è­˜åœ–è­œæ¨¡å¼")
                    print("  'vector <å•é¡Œ>' - å‘é‡RAGæ¨¡å¼") 
                    print("  'hybrid-all <å•é¡Œ>' - å…¨æ··åˆæ¨¡å¼")
                    print("  'compare <å•é¡Œ>' - æ¯”è¼ƒæ‰€æœ‰æ¨¡å¼")
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        print("\næ„Ÿè¬ä½¿ç”¨ RAG å•ç­”ç³»çµ±ï¼")
    
    def _print_hybrid_result(self, result: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å°çŸ¥è­˜åœ–è­œçµæœ
        """
        print(f"\n{'='*60}")
        print(f"å•é¡Œ: {result['query']}")
        print(f"ã€çŸ¥è­˜åœ–è­œæ¨¡å¼ã€‘")
        print(f"{'='*60}")
        
        if result['cypher_query']:
            print(f"\nğŸ”§ LLM ç”Ÿæˆçš„ Cypher æŸ¥è©¢:")
            clean_query = result['cypher_query'].replace('cypher\n', '').strip()
            print(f"   {clean_query}")
        
        if result['context_data']:
            print(f"\nğŸ“Š å¾ Neo4j æª¢ç´¢åˆ°çš„çŸ¥è­˜ ({len(result['context_data'])} é …):")
            for i, item in enumerate(result['context_data'], 1):
                if isinstance(item, dict):
                    subject = item.get('subject', '')
                    predicate = item.get('predicate', '')
                    object_val = item.get('object', '')
                    print(f"   {i}. {subject} â†’ [{predicate}] â†’ {object_val}")
                else:
                    print(f"   {i}. {item}")
        else:
            print(f"\nğŸ“Š æ²’æœ‰æª¢ç´¢åˆ°ç›¸é—œçŸ¥è­˜")
        
        if result['thinking']:
            print(f"\nğŸ¤” AIæ€è€ƒéç¨‹:")
            print(f"{'='*50}")
            print(result['thinking'])
            print(f"{'='*50}")
        
        print(f"\nğŸ¤– çŸ¥è­˜åœ–è­œå›ç­”:")
        print(f"{result['answer']}")
        
        print(f"\nâ±ï¸ åŸ·è¡Œæ™‚é–“: {result['total_time']:.2f} ç§’")
    
    
    def _print_vector_result(self, result: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å°ç´”å‘é‡RAGçµæœ
        """
        print(f"\n{'='*60}")
        print(f"å•é¡Œ: {result['query']}")
        print(f"ã€ç´”å‘é‡RAGæ¨¡å¼ã€‘")
        print(f"{'='*60}")
        
        if result['vector_results']:
            print(f"\nğŸ“Š å¾å‘é‡æ•¸æ“šåº«æª¢ç´¢åˆ°çš„çŸ¥è­˜ ({len(result['vector_results'])} é …):")
            for i, vr in enumerate(result['vector_results'], 1):
                print(f"   {i}. [ç›¸ä¼¼åº¦: {vr['similarity_score']:.3f}] {vr['content'][:500]}...")
                print(f"      ä¾†æº: {vr['metadata'].get('source_file', 'Unknown')}")
        else:
            print(f"\nğŸ“Š æ²’æœ‰æª¢ç´¢åˆ°ç›¸é—œçŸ¥è­˜")
        
        if result['thinking']:
            print(f"\nğŸ¤” AIæ€è€ƒéç¨‹:")
            print(f"{'='*50}")
            print(result['thinking'])
            print(f"{'='*50}")
        
        print(f"\nğŸ¤– å‘é‡RAGå›ç­”:")
        print(f"{result['answer']}")
        
        print(f"\nâ±ï¸ åŸ·è¡Œæ™‚é–“:")
        print(f"   æª¢ç´¢æ™‚é–“: {result['retrieval_time']:.2f} ç§’")
        print(f"   ç”Ÿæˆæ™‚é–“: {result['generation_time']:.2f} ç§’")
        print(f"   ç¸½æ™‚é–“: {result['total_time']:.2f} ç§’")
    
    def _print_hybrid_all_result(self, result: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å°å…¨æ··åˆRAGçµæœ
        """
        print(f"\n{'='*70}")
        print(f"å•é¡Œ: {result['query']}")
        print(f"ã€å…¨æ··åˆRAGæ¨¡å¼ã€‘çŸ¥è­˜åœ–è­œ + å‘é‡æª¢ç´¢")
        print(f"{'='*70}")
        
        if result['cypher_query']:
            print(f"\nğŸ”§ çŸ¥è­˜åœ–è­œCypheræŸ¥è©¢:")
            clean_query = result['cypher_query'].replace('cypher\n', '').strip()
            print(f"   {clean_query}")
        
        if result['context_data']:
            print(f"\nğŸ“Š çŸ¥è­˜åœ–è­œæª¢ç´¢çµæœ ({len(result['context_data'])} é …):")
            for i, item in enumerate(result['context_data'], 1):
                if isinstance(item, dict):
                    subject = item.get('subject', '')
                    predicate = item.get('predicate', '')
                    object_val = item.get('object', '')
                    print(f"   {i}. {subject} â†’ [{predicate}] â†’ {object_val}")
                else:
                    print(f"   {i}. {item}")
        
        if result['vector_results']:
            print(f"\nğŸ” å‘é‡æª¢ç´¢çµæœ ({len(result['vector_results'])} é …):")
            for i, vr in enumerate(result['vector_results'], 1):
                print(f"   {i}. [ç›¸ä¼¼åº¦: {vr['similarity_score']:.3f}] {vr['content'][:500]}...")
                print(f"      ä¾†æº: {vr['metadata'].get('source_file', 'Unknown')}")
        
        if result['thinking']:
            print(f"\nğŸ¤” AIæ€è€ƒéç¨‹:")
            print(f"{'='*50}")
            print(result['thinking'])
            print(f"{'='*50}")
        
        print(f"\nğŸ¤– å…¨æ··åˆRAGå›ç­”:")
        print(f"{result['answer']}")
        
        print(f"\nâ±ï¸ åŸ·è¡Œæ™‚é–“: {result['total_time']:.2f} ç§’")
        print(f"   (æª¢ç´¢: {result['retrieval_time']:.2f}s, ç”Ÿæˆ: {result['generation_time']:.2f}s)")
    
    def _compare_three_modes(self, query: str):
        """
        æ¯”è¼ƒä¸‰ç¨®å¯ç”¨æ¨¡å¼çš„å›ç­”: KG, vector, hybrid-all
        """
        print(f"\n{'='*70}")
        print(f"ä¸‰æ¨¡å¼æ¯”è¼ƒï¼š{query}")
        print(f"{'='*70}")
        
        # 1. çŸ¥è­˜åœ–è­œæ¨¡å¼
        print(f"\nã€æ¨¡å¼ä¸€ï¼šçŸ¥è­˜åœ–è­œ (KG)ã€‘")
        print("-" * 40)
        result1 = self.answer_question(query, use_hybrid=True)
        print(f"å›ç­”: {result1['answer'][:500]}...")
        print(f"æ™‚é–“: {result1['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result1['knowledge_items_count']}")
        
        # 2. ç´”å‘é‡RAGæ¨¡å¼
        if self.vector_available:
            print(f"\nã€æ¨¡å¼äºŒï¼šç´”å‘é‡RAG (vector)ã€‘")
            print("-" * 40)
            result2 = self.answer_question(query, use_vector=True)
            print(f"å›ç­”: {result2['answer'][:500]}...")
            print(f"æ™‚é–“: {result2['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result2['knowledge_items_count']}")
            
            # 3. å…¨æ··åˆæ¨¡å¼
            print(f"\nã€æ¨¡å¼ä¸‰ï¼šå…¨æ··åˆRAG (hybrid-all)ã€‘")
            print("-" * 40)
            result3 = self.answer_question(query, use_hybrid_all=True)
            print(f"å›ç­”: {result3['answer'][:500]}...")
            print(f"æ™‚é–“: {result3['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result3['knowledge_items_count']}")
            
            print(f"\nğŸ’¡ ä¸‰ç¨®æ¨¡å¼å„æœ‰ç‰¹è‰²ï¼Œå¯æ ¹æ“šéœ€æ±‚é¸æ“‡")
        else:
            print(f"\nâš ï¸  å‘é‡RAGä¸å¯ç”¨ï¼Œåƒ…é¡¯ç¤ºçŸ¥è­˜åœ–è­œæ¨¡å¼çµæœ")
    
    def close(self):
        """
        é—œé–‰é€£æ¥
        """
        self.knowledge_retriever.close()
        if self.vector_rag_processor:
            self.vector_rag_processor.close() 