from knowledge_retriever import Neo4jKnowledgeRetriever
from ollama_client import OllamaClient
from vector_rag_processor import VectorRAGProcessor
import time
from typing import Dict, Any
from config import NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD, OLLAMA_BASE_URL, OLLAMA_MODEL

class RAGSystem:
    def __init__(self, 
                 neo4j_uri: str = NEO4J_URI,
                 neo4j_user: str = NEO4J_USER, 
                 neo4j_password: str = NEO4J_PASSWORD,
                 ollama_url: str = OLLAMA_BASE_URL,
                 model_name: str = OLLAMA_MODEL):
        
        self.knowledge_retriever = Neo4jKnowledgeRetriever(neo4j_uri, neo4j_user, neo4j_password)
        self.ollama_client = OllamaClient(ollama_url)
        self.model_name = model_name
        
        # åˆå§‹åŒ–Vector RAGè™•ç†å™¨
        try:
            self.vector_rag_processor = VectorRAGProcessor()
            self.vector_available = True
        except Exception as e:
            print(f"è­¦å‘Š: Vector RAGåˆå§‹åŒ–å¤±æ•—: {e}")
            self.vector_rag_processor = None
            self.vector_available = False
        
        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
        if not self.ollama_client.check_model_available(model_name):
            print(f"è­¦å‘Š: æ¨¡å‹ {model_name} ä¸å¯ç”¨")
            available_models = self.ollama_client.list_models()
            if not available_models.get("error"):
                print("å¯ç”¨æ¨¡å‹:", [m["name"] for m in available_models.get("models", [])])
    
    def answer_question(self, user_query: str, use_rag: bool = True, use_langchain: bool = False, use_hybrid: bool = False, use_vector: bool = False, use_hybrid_all: bool = False) -> Dict[str, Any]:
        """
        å›ç­”ç”¨æˆ¶å•é¡Œ
        """
        start_time = time.time()
        
        result = {
            "query": user_query,
            "use_rag": use_rag,
            "use_langchain": use_langchain,
            "use_hybrid": use_hybrid,
            "use_vector": use_vector,
            "use_hybrid_all": use_hybrid_all,
            "knowledge_context": "",
            "answer": "",
            "retrieval_time": 0,
            "generation_time": 0,
            "total_time": 0,
            "knowledge_items_count": 0,
            "cypher_query": "",
            "context_data": [],
            "vector_results": []
        }
        
        if use_hybrid_all:
            # ä½¿ç”¨æ··åˆæª¢ç´¢æ¨¡å¼ï¼šåŒæ™‚ä½¿ç”¨çŸ¥è­˜åœ–è­œå’Œå‘é‡æª¢ç´¢
            retrieval_start = time.time()
            
            # ç²å–çŸ¥è­˜åœ–è­œçµæœ
            hybrid_result = self.knowledge_retriever.hybrid_search(user_query, self.ollama_client)
            
            # ç²å–å‘é‡æª¢ç´¢çµæœ
            vector_results = []
            if self.vector_available:
                try:
                    vector_search = self.vector_rag_processor.search_documents(user_query, n_results=5)
                    vector_results = vector_search['results']
                except Exception as e:
                    print(f"å‘é‡æª¢ç´¢å¤±æ•—: {e}")
            
            retrieval_time = time.time() - retrieval_start
            
            # çµ„åˆçŸ¥è­˜ä¸Šä¸‹æ–‡
            combined_context = f"CypheræŸ¥è©¢: {hybrid_result['cypher_query']}\næª¢ç´¢åˆ°çš„åœ–è­œæ•¸æ“š: {hybrid_result['context']}\n"
            if vector_results:
                combined_context += "\nå‘é‡æª¢ç´¢çµæœ:\n"
                for i, vr in enumerate(vector_results, 1):
                    combined_context += f"{i}. {vr['content'][:200]}... (ä¾†æº: {vr['metadata'].get('source_file', 'Unknown')})\n"
            
            # ä½¿ç”¨çµ„åˆä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”
            generation_start = time.time()
            detailed_answer = self.ollama_client.rag_generate(
                model=self.model_name,
                user_query=user_query,
                knowledge_context=combined_context,
                temperature=0.7
            )
            generation_time = time.time() - generation_start
            
            result["answer"] = detailed_answer
            result["cypher_query"] = hybrid_result["cypher_query"]
            result["context_data"] = hybrid_result["context"]
            result["vector_results"] = vector_results
            result["knowledge_context"] = combined_context
            result["retrieval_time"] = retrieval_time
            result["generation_time"] = generation_time
            result["knowledge_items_count"] = len(hybrid_result["context"]) + len(vector_results)
            
        elif use_vector:
            # ç´”å‘é‡RAGæ¨¡å¼
            if not self.vector_available:
                result["answer"] = "å‘é‡RAGç³»çµ±ä¸å¯ç”¨ï¼Œè«‹æª¢æŸ¥é…ç½®"
                return result
            
            retrieval_start = time.time()
            vector_search = self.vector_rag_processor.search_documents(user_query, n_results=5)
            retrieval_time = time.time() - retrieval_start
            
            vector_results = vector_search['results']
            
            if vector_results:
                # çµ„ç¹”å‘é‡æª¢ç´¢ä¸Šä¸‹æ–‡
                vector_context = "å¾å‘é‡æ•¸æ“šåº«æª¢ç´¢åˆ°çš„ç›¸é—œä¿¡æ¯:\n"
                for i, vr in enumerate(vector_results, 1):
                    vector_context += f"{i}. {vr['content']} (ç›¸ä¼¼åº¦: {vr['similarity_score']:.3f}, ä¾†æº: {vr['metadata'].get('source_file', 'Unknown')})\n"
                
                # ç”Ÿæˆå›ç­”
                generation_start = time.time()
                answer = self.ollama_client.rag_generate(
                    model=self.model_name,
                    user_query=user_query,
                    knowledge_context=vector_context,
                    temperature=0.7
                )
                generation_time = time.time() - generation_start
                
                result["answer"] = answer
                result["knowledge_context"] = vector_context
                result["vector_results"] = vector_results
                result["knowledge_items_count"] = len(vector_results)
            else:
                result["answer"] = "å‘é‡æ•¸æ“šåº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œä¿¡æ¯"
            
            result["retrieval_time"] = retrieval_time
            result["generation_time"] = generation_time if 'generation_time' in locals() else 0
            
        elif use_hybrid:
            # ä½¿ç”¨æ··åˆRAGæ¨¡å¼ï¼šLangChainæª¢ç´¢ + è‡ªå®šç¾©ç”Ÿæˆ
            retrieval_start = time.time()
            hybrid_result = self.knowledge_retriever.hybrid_search(user_query, self.ollama_client)
            retrieval_time = time.time() - retrieval_start
            
            result["answer"] = hybrid_result["answer"]
            result["cypher_query"] = hybrid_result["cypher_query"]
            result["context_data"] = hybrid_result["context"]
            result["knowledge_context"] = f"CypheræŸ¥è©¢: {hybrid_result['cypher_query']}\næª¢ç´¢åˆ°çš„æ•¸æ“š: {hybrid_result['context']}"
            result["retrieval_time"] = retrieval_time
            result["generation_time"] = 0  # åŒ…å«åœ¨retrieval_timeä¸­
            result["knowledge_items_count"] = len(hybrid_result["context"]) if isinstance(hybrid_result["context"], list) else 0
            
        elif use_langchain:
            # ä½¿ç”¨ LangChain GraphCypherQAChain
            retrieval_start = time.time()
            langchain_result = self.knowledge_retriever.langchain_search(user_query)
            retrieval_time = time.time() - retrieval_start
            
            result["answer"] = langchain_result["answer"]
            result["cypher_query"] = langchain_result["cypher_query"]
            result["context_data"] = langchain_result["context"]
            result["knowledge_context"] = f"CypheræŸ¥è©¢: {langchain_result['cypher_query']}\næª¢ç´¢åˆ°çš„æ•¸æ“š: {langchain_result['context']}"
            result["retrieval_time"] = retrieval_time
            result["generation_time"] = 0  # LangChain å…§éƒ¨è™•ç†
            result["knowledge_items_count"] = len(langchain_result["context"]) if isinstance(langchain_result["context"], list) else 0
            
        elif use_rag:
            # æ­¥é©Ÿ 1: å¾ Neo4j æª¢ç´¢ç›¸é—œçŸ¥è­˜
            retrieval_start = time.time()
            knowledge_context = self.knowledge_retriever.comprehensive_search(user_query)
            retrieval_time = time.time() - retrieval_start
            
            result["knowledge_context"] = knowledge_context
            result["retrieval_time"] = retrieval_time
            
            # è¨ˆç®—çŸ¥è­˜é …ç›®æ•¸é‡
            if "æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„çŸ¥è­˜" not in knowledge_context:
                # ç°¡å–®è¨ˆç®—çŸ¥è­˜é …ç›®æ•¸é‡ï¼ˆä»¥ç·¨è™Ÿé–‹å§‹çš„è¡Œï¼‰
                lines = knowledge_context.split('\n')
                knowledge_items = [line for line in lines if line.strip() and any(line.strip().startswith(f"{i}.") for i in range(1, 20))]
                result["knowledge_items_count"] = len(knowledge_items)
            
            # æ­¥é©Ÿ 2: ä½¿ç”¨ RAG ç”Ÿæˆå›ç­”
            generation_start = time.time()
            answer = self.ollama_client.rag_generate(
                model=self.model_name,
                user_query=user_query,
                knowledge_context=knowledge_context
            )
            generation_time = time.time() - generation_start
            
            result["answer"] = answer
            result["generation_time"] = generation_time
        
        else:
            # ä¸ä½¿ç”¨ RAGï¼Œç›´æ¥ç”Ÿæˆå›ç­”
            generation_start = time.time()
            answer = self.ollama_client.simple_generate(
                model=self.model_name,
                user_query=user_query
            )
            generation_time = time.time() - generation_start
            
            result["answer"] = answer
            result["generation_time"] = generation_time
        
        result["total_time"] = time.time() - start_time
        return result
    
    def compare_rag_vs_normal(self, user_query: str) -> Dict[str, Any]:
        """
        æ¯”è¼ƒä½¿ç”¨ RAG å’Œä¸ä½¿ç”¨ RAG çš„å›ç­”
        """
        print("æ­£åœ¨ç”Ÿæˆ RAG å›ç­”...")
        rag_result = self.answer_question(user_query, use_rag=True)
        
        print("æ­£åœ¨ç”Ÿæˆæ™®é€šå›ç­”...")
        normal_result = self.answer_question(user_query, use_rag=False)
        
        return {
            "query": user_query,
            "rag_result": rag_result,
            "normal_result": normal_result
        }
    

    
    def interactive_qa(self):
        """
        äº’å‹•å¼å•ç­” - ç°¡åŒ–ç‰ˆï¼Œç›´æ¥ä½¿ç”¨ LangChain
        """
        print("=== RAG çŸ¥è­˜å•ç­”ç³»çµ± (å¢å¼·ç‰ˆ) ===")
        print("ğŸ’¡ ä½¿ç”¨ LangChain + Ollama + Neo4j çŸ¥è­˜åœ–è­œ + Vector RAG")
        print("\nğŸ”§ å¯ç”¨å‘½ä»¤:")
        print("  ç›´æ¥è¼¸å…¥å•é¡Œ â†’ ä½¿ç”¨æ”¹é€²çš„LangChainæ¨¡å¼")
        print("  'hybrid <å•é¡Œ>' â†’ ä½¿ç”¨æ··åˆRAGæ¨¡å¼(æ¨è–¦)")
        print("  'vector <å•é¡Œ>' â†’ ä½¿ç”¨ç´”å‘é‡RAGæ¨¡å¼")
        print("  'hybrid-all <å•é¡Œ>' â†’ ä½¿ç”¨å…¨æ··åˆæ¨¡å¼(çŸ¥è­˜åœ–è­œ+å‘é‡)")
        print("  'langchain <å•é¡Œ>' â†’ ä½¿ç”¨åŸå§‹LangChainæ¨¡å¼")
        print("  'compare <å•é¡Œ>' â†’ æ¯”è¼ƒå¤šç¨®æ¨¡å¼")
        print("  'quit' æˆ– 'exit' â†’ é€€å‡ºç³»çµ±")
        
        if self.vector_available:
            vector_stats = self.vector_rag_processor.get_database_stats()
            print(f"\nğŸ“Š å‘é‡æ•¸æ“šåº«ç‹€æ…‹: {vector_stats['total_chunks']} chunks, {vector_stats['unique_files']} æ–‡ä»¶")
        else:
            print("\nâš ï¸  å‘é‡RAGä¸å¯ç”¨")
        
        print("-" * 70)
        
        while True:
            try:
                user_input = input("\nè«‹è¼¸å…¥å•é¡Œ: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    break
                
                elif user_input.startswith('hybrid '):
                    # ä½¿ç”¨æ··åˆRAGæ¨¡å¼
                    query = user_input[7:].strip()
                    if query:
                        result = self.answer_question(query, use_rag=False, use_langchain=False, use_hybrid=True)
                        self._print_hybrid_result(result)
                    else:
                        print("è«‹æä¾›å•é¡Œ")
                
                elif user_input.startswith('langchain '):
                    # ä½¿ç”¨åŸå§‹LangChainæ¨¡å¼
                    query = user_input[10:].strip()
                    if query:
                        result = self.answer_question(query, use_rag=False, use_langchain=True)
                        self._print_langchain_result(result)
                    else:
                        print("è«‹æä¾›å•é¡Œ")
                
                elif user_input.startswith('vector '):
                    # ä½¿ç”¨ç´”å‘é‡RAGæ¨¡å¼
                    query = user_input[7:].strip()
                    if query:
                        if self.vector_available:
                            result = self.answer_question(query, use_rag=False, use_langchain=False, use_vector=True)
                            self._print_vector_result(result)
                        else:
                            print("å‘é‡RAGç³»çµ±ä¸å¯ç”¨")
                    else:
                        print("è«‹æä¾›å•é¡Œ")
                
                elif user_input.startswith('hybrid-all '):
                    # ä½¿ç”¨å…¨æ··åˆæ¨¡å¼
                    query = user_input[11:].strip()
                    if query:
                        if self.vector_available:
                            result = self.answer_question(query, use_rag=False, use_langchain=False, use_hybrid_all=True)
                            self._print_hybrid_all_result(result)
                        else:
                            print("å‘é‡RAGç³»çµ±ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨çŸ¥è­˜åœ–è­œæ¨¡å¼")
                            result = self.answer_question(query, use_rag=False, use_langchain=False, use_hybrid=True)
                            self._print_hybrid_result(result)
                    else:
                        print("è«‹æä¾›å•é¡Œ")
                
                elif user_input.startswith('compare '):
                    # æ¯”è¼ƒå¤šç¨®æ¨¡å¼
                    query = user_input[8:].strip()
                    if query:
                        self._compare_all_modes(query)
                    else:
                        print("è«‹æä¾›å•é¡Œ")
                
                elif user_input:
                    # ç›´æ¥ä½¿ç”¨æ”¹é€²çš„LangChainæ¨¡å¼
                    result = self.answer_question(user_input, use_rag=False, use_langchain=True)
                    self._print_simple_langchain_answer(result)
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        print("\næ„Ÿè¬ä½¿ç”¨ RAG å•ç­”ç³»çµ±ï¼")
    
    def _print_rag_result(self, result: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å° RAG çµæœ
        """
        print(f"\n{'='*50}")
        print(f"å•é¡Œ: {result['query']}")
        print(f"{'='*50}")
        
        if result['use_rag']:
            print(f"æª¢ç´¢åˆ° {result['knowledge_items_count']} å€‹ç›¸é—œçŸ¥è­˜é …ç›®")
            print(f"æª¢ç´¢æ™‚é–“: {result['retrieval_time']:.2f} ç§’")
            
            if result['knowledge_items_count'] > 0:
                print(f"\næª¢ç´¢åˆ°çš„çŸ¥è­˜:")
                print(result['knowledge_context'])
        
        print(f"\nå›ç­”:")
        print(result['answer'])
        
        print(f"\nç”Ÿæˆæ™‚é–“: {result['generation_time']:.2f} ç§’")
        print(f"ç¸½æ™‚é–“: {result['total_time']:.2f} ç§’")
    
    def _print_comparison_result(self, result: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å°æ¯”è¼ƒçµæœ
        """
        print(f"\n{'='*50}")
        print(f"å•é¡Œ: {result['query']}")
        print(f"{'='*50}")
        
        print(f"\nã€RAG å›ç­”ã€‘(æª¢ç´¢åˆ° {result['rag_result']['knowledge_items_count']} å€‹çŸ¥è­˜é …ç›®)")
        print(result['rag_result']['answer'])
        print(f"æ™‚é–“: {result['rag_result']['total_time']:.2f} ç§’")
        
        print(f"\nã€æ™®é€šå›ç­”ã€‘")
        print(result['normal_result']['answer'])
        print(f"æ™‚é–“: {result['normal_result']['total_time']:.2f} ç§’")
    
    def _print_entity_info(self, info: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å°å¯¦é«”ä¿¡æ¯
        """
        print(f"\nå¯¦é«”: {info['entity']}")
        print("-" * 30)
        
        if info['relations']:
            print("é—œä¿‚:")
            for i, rel in enumerate(info['relations'], 1):
                direction = "â†’" if rel['direction'] == 'outgoing' else "â†"
                print(f"  {i}. {rel['entity']} {direction} [{rel['relation']}] {direction} {rel['related_entity']}")
        else:
            print("æ²’æœ‰æ‰¾åˆ°ç›¸é—œé—œä¿‚")
        
        if info['neighbors']:
            print("\né„°å±…ç¯€é»:")
            for i, neighbor in enumerate(info['neighbors'], 1):
                print(f"  {i}. {neighbor['neighbor']} (é—œä¿‚: {neighbor['relation']})")
    
    def _print_simple_answer(self, result: Dict[str, Any]):
        """
        ç°¡åŒ–çš„ç­”æ¡ˆé¡¯ç¤ºï¼ˆåªé¡¯ç¤ºç­”æ¡ˆï¼Œä¸é¡¯ç¤ºæª¢ç´¢è©³æƒ…ï¼‰
        """
        print(f"\nå•é¡Œ: {result['query']}")
        print("-" * 50)
        
        if result['use_rag'] and result['knowledge_items_count'] > 0:
            print(f"âœ“ å·²å¾çŸ¥è­˜åº«æª¢ç´¢åˆ° {result['knowledge_items_count']} å€‹ç›¸é—œä¿¡æ¯")
        
        print(f"\nå›ç­”:")
        print(result['answer'])
        
        if result['use_rag'] and result['knowledge_items_count'] == 0:
            print("\n(æ³¨æ„: çŸ¥è­˜åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œä¿¡æ¯ï¼Œä»¥ä¸Šç‚ºæ¨¡å‹çš„ä¸€èˆ¬çŸ¥è­˜å›ç­”)")
    
    def _print_langchain_result(self, result: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å° LangChain çµæœ
        """
        print(f"\n{'='*60}")
        print(f"å•é¡Œ: {result['query']}")
        print(f"ã€ä½¿ç”¨ LangChain GraphCypherQAChainã€‘")
        print(f"{'='*60}")
        
        if result['cypher_query']:
            print(f"\nğŸ”§ LLM ç”Ÿæˆçš„ Cypher æŸ¥è©¢:")
            # æ¸…ç† cypher å‰ç¶´
            clean_query = result['cypher_query'].replace('cypher\n', '').strip()
            print(f"   {clean_query}")
        
        if result['context_data']:
            print(f"\nğŸ“Š å¾ Neo4j æª¢ç´¢åˆ°çš„çŸ¥è­˜ ({len(result['context_data'])} é …):")
            for i, item in enumerate(result['context_data'], 1):
                if isinstance(item, dict):
                    subject = item.get('subject', '')
                    predicate = item.get('predicate', '')
                    object_val = item.get('object', '')
                    print(f"   {i}. {subject} â†’ [{predicate}] â†’ {object_val}")
                else:
                    print(f"   {i}. {item}")
        else:
            print(f"\nğŸ“Š æ²’æœ‰æª¢ç´¢åˆ°ç›¸é—œçŸ¥è­˜")
        
        print(f"\nğŸ¤– LLM æœ€çµ‚å›ç­”:")
        print(f"   {result['answer']}")
        
        print(f"\nâ±ï¸ åŸ·è¡Œæ™‚é–“:")
        print(f"   æª¢ç´¢æ™‚é–“: {result['retrieval_time']:.2f} ç§’")
        print(f"   ç¸½æ™‚é–“: {result['total_time']:.2f} ç§’")
        
    def _print_simple_langchain_answer(self, result: Dict[str, Any]):
        """
        ç°¡æ½”ç‰ˆçš„ LangChain çµæœé¡¯ç¤º
        """
        print(f"\nğŸ¤– å›ç­”:")
        print(f"   {result['answer']}")
        
        if result['context_data']:
            print(f"\nğŸ“š åŸºæ–¼ {len(result['context_data'])} å€‹çŸ¥è­˜é …ç›® (åŸ·è¡Œæ™‚é–“: {result['total_time']:.2f}s)")
        else:
            print(f"\nâš ï¸  çŸ¥è­˜åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œä¿¡æ¯ (åŸ·è¡Œæ™‚é–“: {result['total_time']:.2f}s)")
    
    def _print_hybrid_result(self, result: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å°æ··åˆRAGçµæœ
        """
        print(f"\n{'='*60}")
        print(f"å•é¡Œ: {result['query']}")
        print(f"ã€æ··åˆRAGæ¨¡å¼ã€‘LangChainæª¢ç´¢ + è‡ªå®šç¾©ç”Ÿæˆ")
        print(f"{'='*60}")
        
        if result['cypher_query']:
            print(f"\nğŸ”§ LLM ç”Ÿæˆçš„ Cypher æŸ¥è©¢:")
            clean_query = result['cypher_query'].replace('cypher\n', '').strip()
            print(f"   {clean_query}")
        
        if result['context_data']:
            print(f"\nğŸ“Š å¾ Neo4j æª¢ç´¢åˆ°çš„çŸ¥è­˜ ({len(result['context_data'])} é …):")
            for i, item in enumerate(result['context_data'], 1):
                if isinstance(item, dict):
                    subject = item.get('subject', '')
                    predicate = item.get('predicate', '')
                    object_val = item.get('object', '')
                    print(f"   {i}. {subject} â†’ [{predicate}] â†’ {object_val}")
                else:
                    print(f"   {i}. {item}")
        else:
            print(f"\nğŸ“Š æ²’æœ‰æª¢ç´¢åˆ°ç›¸é—œçŸ¥è­˜")
        
        print(f"\nğŸ¤– æ··åˆRAGç”Ÿæˆçš„è©³ç´°å›ç­”:")
        print(f"{result['answer']}")
        
        print(f"\nâ±ï¸ åŸ·è¡Œæ™‚é–“: {result['total_time']:.2f} ç§’")
    
    def _compare_modes(self, query: str):
        """
        æ¯”è¼ƒä¸‰ç¨®æ¨¡å¼çš„å›ç­”
        """
        print(f"\n{'='*70}")
        print(f"ä¸‰æ¨¡å¼æ¯”è¼ƒï¼š{query}")
        print(f"{'='*70}")
        
        # 1. æ”¹é€²çš„LangChainæ¨¡å¼
        print(f"\nã€æ¨¡å¼ä¸€ï¼šæ”¹é€²çš„LangChainã€‘")
        print("-" * 40)
        result1 = self.answer_question(query, use_rag=False, use_langchain=True)
        print(f"å›ç­”: {result1['answer']}")
        print(f"æ™‚é–“: {result1['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result1['knowledge_items_count']}")
        
        # 2. æ··åˆRAGæ¨¡å¼
        print(f"\nã€æ¨¡å¼äºŒï¼šæ··åˆRAG (æ¨è–¦)ã€‘")
        print("-" * 40)
        result2 = self.answer_question(query, use_rag=False, use_langchain=False, use_hybrid=True)
        print(f"å›ç­”: {result2['answer']}")
        print(f"æ™‚é–“: {result2['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result2['knowledge_items_count']}")
        
        # 3. å‚³çµ±RAGæ¨¡å¼
        print(f"\nã€æ¨¡å¼ä¸‰ï¼šå‚³çµ±RAGã€‘")
        print("-" * 40)
        result3 = self.answer_question(query, use_rag=True, use_langchain=False)
        print(f"å›ç­”: {result3['answer']}")
        print(f"æ™‚é–“: {result3['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result3['knowledge_items_count']}")
        
        print(f"\nğŸ’¡ æ¨è–¦ä½¿ç”¨æ··åˆRAGæ¨¡å¼ç²å¾—æœ€ä½³æ•ˆæœ")
    
    def _print_vector_result(self, result: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å°ç´”å‘é‡RAGçµæœ
        """
        print(f"\n{'='*60}")
        print(f"å•é¡Œ: {result['query']}")
        print(f"ã€ç´”å‘é‡RAGæ¨¡å¼ã€‘")
        print(f"{'='*60}")
        
        if result['vector_results']:
            print(f"\nğŸ“Š å¾å‘é‡æ•¸æ“šåº«æª¢ç´¢åˆ°çš„çŸ¥è­˜ ({len(result['vector_results'])} é …):")
            for i, vr in enumerate(result['vector_results'], 1):
                print(f"   {i}. [ç›¸ä¼¼åº¦: {vr['similarity_score']:.3f}] {vr['content'][:100]}...")
                print(f"      ä¾†æº: {vr['metadata'].get('source_file', 'Unknown')}")
        else:
            print(f"\nğŸ“Š æ²’æœ‰æª¢ç´¢åˆ°ç›¸é—œçŸ¥è­˜")
        
        print(f"\nğŸ¤– å‘é‡RAGå›ç­”:")
        print(f"{result['answer']}")
        
        print(f"\nâ±ï¸ åŸ·è¡Œæ™‚é–“:")
        print(f"   æª¢ç´¢æ™‚é–“: {result['retrieval_time']:.2f} ç§’")
        print(f"   ç”Ÿæˆæ™‚é–“: {result['generation_time']:.2f} ç§’")
        print(f"   ç¸½æ™‚é–“: {result['total_time']:.2f} ç§’")
    
    def _print_hybrid_all_result(self, result: Dict[str, Any]):
        """
        æ ¼å¼åŒ–æ‰“å°å…¨æ··åˆRAGçµæœ
        """
        print(f"\n{'='*70}")
        print(f"å•é¡Œ: {result['query']}")
        print(f"ã€å…¨æ··åˆRAGæ¨¡å¼ã€‘çŸ¥è­˜åœ–è­œ + å‘é‡æª¢ç´¢")
        print(f"{'='*70}")
        
        if result['cypher_query']:
            print(f"\nğŸ”§ çŸ¥è­˜åœ–è­œCypheræŸ¥è©¢:")
            clean_query = result['cypher_query'].replace('cypher\n', '').strip()
            print(f"   {clean_query}")
        
        if result['context_data']:
            print(f"\nğŸ“Š çŸ¥è­˜åœ–è­œæª¢ç´¢çµæœ ({len(result['context_data'])} é …):")
            for i, item in enumerate(result['context_data'], 1):
                if isinstance(item, dict):
                    subject = item.get('subject', '')
                    predicate = item.get('predicate', '')
                    object_val = item.get('object', '')
                    print(f"   {i}. {subject} â†’ [{predicate}] â†’ {object_val}")
                else:
                    print(f"   {i}. {item}")
        
        if result['vector_results']:
            print(f"\nğŸ” å‘é‡æª¢ç´¢çµæœ ({len(result['vector_results'])} é …):")
            for i, vr in enumerate(result['vector_results'], 1):
                print(f"   {i}. [ç›¸ä¼¼åº¦: {vr['similarity_score']:.3f}] {vr['content'][:80]}...")
                print(f"      ä¾†æº: {vr['metadata'].get('source_file', 'Unknown')}")
        
        print(f"\nğŸ¤– å…¨æ··åˆRAGå›ç­”:")
        print(f"{result['answer']}")
        
        print(f"\nâ±ï¸ åŸ·è¡Œæ™‚é–“: {result['total_time']:.2f} ç§’")
        print(f"   (æª¢ç´¢: {result['retrieval_time']:.2f}s, ç”Ÿæˆ: {result['generation_time']:.2f}s)")
    
    def _compare_all_modes(self, query: str):
        """
        æ¯”è¼ƒæ‰€æœ‰å¯ç”¨æ¨¡å¼çš„å›ç­”
        """
        print(f"\n{'='*80}")
        print(f"å¤šæ¨¡å¼æ¯”è¼ƒï¼š{query}")
        print(f"{'='*80}")
        
        # 1. æ”¹é€²çš„LangChainæ¨¡å¼
        print(f"\nã€æ¨¡å¼ä¸€ï¼šçŸ¥è­˜åœ–è­œLangChainã€‘")
        print("-" * 40)
        result1 = self.answer_question(query, use_rag=False, use_langchain=True)
        print(f"å›ç­”: {result1['answer'][:200]}...")
        print(f"æ™‚é–“: {result1['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result1['knowledge_items_count']}")
        
        # 2. æ··åˆRAGæ¨¡å¼
        print(f"\nã€æ¨¡å¼äºŒï¼šçŸ¥è­˜åœ–è­œæ··åˆRAGã€‘")
        print("-" * 40)
        result2 = self.answer_question(query, use_rag=False, use_langchain=False, use_hybrid=True)
        print(f"å›ç­”: {result2['answer'][:200]}...")
        print(f"æ™‚é–“: {result2['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result2['knowledge_items_count']}")
        
        # 3. ç´”å‘é‡RAGæ¨¡å¼
        if self.vector_available:
            print(f"\nã€æ¨¡å¼ä¸‰ï¼šç´”å‘é‡RAGã€‘")
            print("-" * 40)
            result3 = self.answer_question(query, use_rag=False, use_langchain=False, use_vector=True)
            print(f"å›ç­”: {result3['answer'][:200]}...")
            print(f"æ™‚é–“: {result3['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result3['knowledge_items_count']}")
            
            # 4. å…¨æ··åˆæ¨¡å¼
            print(f"\nã€æ¨¡å¼å››ï¼šå…¨æ··åˆRAG (æ¨è–¦)ã€‘")
            print("-" * 40)
            result4 = self.answer_question(query, use_rag=False, use_langchain=False, use_hybrid_all=True)
            print(f"å›ç­”: {result4['answer'][:200]}...")
            print(f"æ™‚é–“: {result4['total_time']:.2f}s | çŸ¥è­˜é …ç›®: {result4['knowledge_items_count']}")
            
            print(f"\nğŸ’¡ æ¨è–¦ä½¿ç”¨å…¨æ··åˆRAGæ¨¡å¼ç²å¾—æœ€ä½³æ•ˆæœ")
        else:
            print(f"\nâš ï¸  å‘é‡RAGä¸å¯ç”¨ï¼Œåƒ…æ¯”è¼ƒçŸ¥è­˜åœ–è­œæ¨¡å¼")
    
    def close(self):
        """
        é—œé–‰é€£æ¥
        """
        self.knowledge_retriever.close()
        if self.vector_rag_processor:
            self.vector_rag_processor.close() 