import requests
import json
import re
from typing import Optional, Dict, Any, Tuple
from config import OLLAMA_BASE_URL, MODEL_TEMPERATURE, MODEL_NUM_PREDICT, RAG_COT_PROMPT

class OllamaClient:
    def __init__(self, base_url: str = OLLAMA_BASE_URL):
        self.base_url = base_url
        self.api_url = f"{base_url}/api"
    
    def generate(self, 
                 model: str,
                 prompt: str,
                 stream: bool = False,
                 temperature: float = 0.7,
                 max_tokens: Optional[int] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Ollama ç”Ÿæˆå›æ‡‰
        """
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": stream,
            "options": {
                "temperature": temperature,
                "num_predict": -1  # é è¨­ç‚ºç„¡é™åˆ¶
            }
        }
        
        if max_tokens and max_tokens > 0:
            payload["options"]["num_predict"] = max_tokens
        else:
            # ä¸è¨­ç½®num_predicté™åˆ¶ï¼Œè®“æ¨¡å‹è‡ªç”±ç”Ÿæˆ
            payload["options"]["num_predict"] = -1
        
        try:
            response = requests.post(
                f"{self.api_url}/generate",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=600  # 10åˆ†é˜è¶…æ™‚ï¼Œçµ¦é•·æ–‡æœ¬ç”Ÿæˆæ›´å¤šæ™‚é–“
            )
            response.raise_for_status()
            
            return response.json()
        
        except requests.exceptions.RequestException as e:
            return {
                "error": f"è«‹æ±‚éŒ¯èª¤: {str(e)}",
                "response": None
            }
        except json.JSONDecodeError as e:
            return {
                "error": f"JSON è§£æéŒ¯èª¤: {str(e)}",
                "response": None
            }
    
    def chat(self, 
             model: str,
             messages: list,
             stream: bool = False,
             temperature: float = 0.7) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Ollama èŠå¤© API
        """
        payload = {
            "model": model,
            "messages": messages,
            "stream": stream,
            "options": {
                "temperature": temperature,
                "num_predict": -1  # é è¨­ç‚ºç„¡é™åˆ¶
            }
        }
        
        try:
            response = requests.post(
                f"{self.api_url}/chat",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=600  # 10åˆ†é˜è¶…æ™‚ï¼Œçµ¦é•·æ–‡æœ¬ç”Ÿæˆæ›´å¤šæ™‚é–“
            )
            response.raise_for_status()
            
            return response.json()
        
        except requests.exceptions.RequestException as e:
            return {
                "error": f"è«‹æ±‚éŒ¯èª¤: {str(e)}",
                "response": None
            }
        except json.JSONDecodeError as e:
            return {
                "error": f"JSON è§£æéŒ¯èª¤: {str(e)}",
                "response": None
            }
    
    def list_models(self) -> Dict[str, Any]:
        """
        åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹
        """
        try:
            response = requests.get(f"{self.api_url}/tags")
            response.raise_for_status()
            return response.json()
        
        except requests.exceptions.RequestException as e:
            return {
                "error": f"è«‹æ±‚éŒ¯èª¤: {str(e)}",
                "models": []
            }
    
    def check_model_available(self, model_name: str) -> bool:
        """
        æª¢æŸ¥æŒ‡å®šæ¨¡å‹æ˜¯å¦å¯ç”¨
        """
        models_info = self.list_models()
        if "error" in models_info:
            return False
        
        available_models = [model["name"] for model in models_info.get("models", [])]
        return model_name in available_models
    
    def _parse_cot_response(self, response_text: str) -> Tuple[str, str]:
        """
        è§£æCoTå›æ‡‰ï¼Œåˆ†é›¢æ€è€ƒéç¨‹å’Œæœ€çµ‚ç­”æ¡ˆ
        è¿”å›: (thinking, answer)
        """
        # å˜—è©¦åŒ¹é… <thinking>...</thinking> å’Œ <answer>...</answer> æ ¼å¼
        thinking_match = re.search(r'<thinking>(.*?)</thinking>', response_text, re.DOTALL)
        answer_match = re.search(r'<answer>(.*?)</answer>', response_text, re.DOTALL)
        
        thinking = ""
        answer = ""
        
        if thinking_match:
            thinking = thinking_match.group(1).strip()
        
        if answer_match:
            answer = answer_match.group(1).strip()
        else:
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™ç±¤æ ¼å¼ï¼Œå˜—è©¦å…¶ä»–æ ¼å¼æˆ–ä½¿ç”¨æ•´å€‹å›æ‡‰ä½œç‚ºç­”æ¡ˆ
            if thinking:
                # å¦‚æœæœ‰thinkingä½†æ²’æœ‰answeræ¨™ç±¤ï¼Œå–thinkingå¾Œé¢çš„å…§å®¹ä½œç‚ºç­”æ¡ˆ
                answer_start = response_text.find('</thinking>') + len('</thinking>')
                if answer_start < len(response_text):
                    answer = response_text[answer_start:].strip()
            else:
                # å®Œå…¨æ²’æœ‰æ¨™ç±¤æ ¼å¼ï¼Œæ•´å€‹å›æ‡‰ä½œç‚ºç­”æ¡ˆ
                answer = response_text.strip()
        
        return thinking, answer
    
    def rag_generate(self,
                     model: str,
                     user_query: str,
                     knowledge_context: str,
                     temperature: float = 0.7) -> Dict[str, str]:
        """
        åŸºæ–¼ RAG çš„ç”Ÿæˆï¼šçµåˆç”¨æˆ¶æŸ¥è©¢å’ŒçŸ¥è­˜ä¸Šä¸‹æ–‡
        è¿”å›åŒ…å«thinkingå’Œanswerçš„å­—å…¸
        """
        # æ§‹å»ºå¸¶æœ‰CoTçš„RAG promptï¼Œä½¿ç”¨configä¸­çš„æ¨¡æ¿
        rag_prompt = RAG_COT_PROMPT.format(
            knowledge_context=knowledge_context,
            user_query=user_query
        )

        result = self.generate(
            model=model,
            prompt=rag_prompt,
            temperature=temperature,
            stream=False
        )
        
        if "error" in result:
            return {
                "thinking": "ç”Ÿæˆéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤",
                "answer": f"ç”Ÿæˆå›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤: {result['error']}"
            }
        
        response_text = result.get("response", "ç„¡æ³•ç”Ÿæˆå›ç­”")
        thinking, answer = self._parse_cot_response(response_text)
        
        # åœ¨çµ‚ç«¯logæ€è€ƒéç¨‹
        if thinking:
            print(f"\nğŸ¤” AIæ€è€ƒéç¨‹:")
            print(f"{'='*50}")
            print(thinking)
            print(f"{'='*50}")
        
        return {
            "thinking": thinking,
            "answer": answer if answer else response_text
        }
    
    def simple_generate(self, 
                       model: str,
                       user_query: str,
                       temperature: float = 0.7) -> str:
        """
        ç°¡å–®ç”Ÿæˆï¼ˆä¸ä½¿ç”¨ RAGï¼‰
        """
        result = self.generate(
            model=model,
            prompt=user_query,
            temperature=temperature,
            stream=False
        )
        
        if "error" in result:
            return f"ç”Ÿæˆå›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤: {result['error']}"
        
        return result.get("response", "ç„¡æ³•ç”Ÿæˆå›ç­”") 